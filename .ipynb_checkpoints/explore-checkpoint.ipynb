{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87384b62-790f-4e50-a787-e2f113659c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from readability import Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f228fca1-f1e9-4160-a971-f7ef8dc8738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Originally, all the metrics were created for the English language and the education system of the United States. In ClickHelp, the metrics are available for all languages. Because of this, school levels and age ranges may be off for other languages. But the relative values will still be correct, so you can compare the readability of two different topics that use the same language. For example, if your topic got 100 according to Flesch Reading Ease, and another topic got 80, it means that the text of the second topic is more difficult to read, than the text of the first one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2ab1b28-8ca5-46f8-90a3-15d633b5dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Readability(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "259e41e4-4df7-48d0-8af7-fa9b24f84a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.flesch_kincaid().grade_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b5fc47-7b90-49d4-a28a-83524d144cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.ari().grade_levels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a8fc8f5-8337-40ed-b8bd-7ac858bcefa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.coleman_liau().grade_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79e0c5ca-2715-4801-ac9b-da7cace12714",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadabilityException",
     "evalue": "SMOG requires 30 sentences. 5 found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadabilityException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_sentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgrade_level\n",
      "File \u001b[0;32m/projects/klybarge/health_literacy/lit_venv/lib/python3.8/site-packages/readability/readability.py:42\u001b[0m, in \u001b[0;36mReadability.smog\u001b[0;34m(self, all_sentences)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msmog\u001b[39m(\u001b[38;5;28mself\u001b[39m,all_sentences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"SMOG Index.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    `all_sentences` indicates whether SMOG should use a sample of 30 sentences, as described in the original paper, or if it should use all sentences in the text\"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSmog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statistics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_analyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43mall_sentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_sentences\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mscore()\n",
      "File \u001b[0;32m/projects/klybarge/health_literacy/lit_venv/lib/python3.8/site-packages/readability/scorers/smog.py:24\u001b[0m, in \u001b[0;36mSmog.__init__\u001b[0;34m(self, stats, sentences, all_sentences)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mComputes the SMOG readability score (Harry McLaughlin, 1969 https://ogg.osu.edu/media/documents/health_lit/WRRSMOG_Readability_Formula_G._Harry_McLaughlin__1969_.pdf)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03mIf all_sentences is false, computes the score as described in McLaughlin, 1969, using exactly 30 sentences\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03mIf all_sentences is true, adjusts the score to use all sentences in the text\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stats\u001b[38;5;241m.\u001b[39mnum_sentences \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m30\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadabilityException(\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMOG requires 30 sentences. \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m found\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;241m.\u001b[39mformat(stats\u001b[38;5;241m.\u001b[39mnum_sentences))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stats \u001b[38;5;241m=\u001b[39m stats\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_sentences \u001b[38;5;241m=\u001b[39m all_sentences\n",
      "\u001b[0;31mReadabilityException\u001b[0m: SMOG requires 30 sentences. 5 found"
     ]
    }
   ],
   "source": [
    "r.smog(all_sentences=True).grade_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028cd98d-c2e8-47d5-8128-5468599b9cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
